# Chapter 2: Prepare

## 1. Data sources

For this analysis, I am using two data sources, which provide different perspectives on user trends and relationships with their smart devices:

- **A) Fitbit fitness tracker dataset (Kaggle)**

Available [here](https://www.kaggle.com/datasets/arashnic/fitbit), this dataset, recommended by Bellabeat COO, was generated by respondents to a distributed survey via Amazon Mechanical Turk between March 12, 2016, and May 12, 2016. Thirty eligible Fitbit users consented to share their personal tracker data. Individual reports can be parsed by export session ID or timestamp.

However, because of this dataset's limitations (small sample size, data collected in 2016, and lack of gender differentiation), I looked for a complementary data source (see below).

- **B) Survey dataset about people's relationships wwith their smart devices (MDPI)**

Available [here](https://www.mdpi.com/2306-5729/9/4/56), this dataset includes survey responses from over 500 individuals, collected between May and July 2020. The larger, more recent sample makes it more representative and relevant. Additionally, the survey asked respondents whether they were male (1) or female (2), which makes it better suited to Bellabeat’s focus on women. Lastly, this dataset adds a psychological dimension to the analysis by exploring user attitudes and interactions with their smart devices, which is good addition to the Fitbit data.

## 2. Data organization

### Overall structure for the Bellabeat project

The project is organized as follows:

BELLABEAT: Project main directory.
Contains four main branches (DATA, SCRIPTS, IMAGES, REPORTS):

  - DATA: All the datasets used in this project
    - VAULT: Original, unmodified datasets (Fitbit and Survey)
    - Fitbit: Working directory for Fitbit data
       - Fitbit_Complete_Data: Complete Fitbit data, before cleaning
       - Cleaned_Fitbit: Cleaned Fitbit data, ready for analysis
       - BigQuery_Exports: Files exported from BigQuery
    - Survey: Working directory for Survey data
       - Survey_Data: Survey data, before cleaning
       - Cleaned_Survey: Cleaned Survey data, ready for analysis
       - BigQuery_Exports: Files exported from BigQuery

  - SCRIPTS: All the scripts used in this project
    - R: R scripts
    - Python: Python scripts
    - SQL: SQL queries (BigQuery) 
    - Shell: Shell scripts (bash) 
     
  - IMAGES: All the images and plots in this project
  - REPORTS: All the reports made in this project


## 3. Preparing the datasets

### A) Fitbit

The original Fitbit dataset unzips into 2 separate folders:

`Fitabase Data 3.12.16 - 4.11.16` 
and 
`Fitabase Data 4.12.16 - 5.12.16`

Many files from the first Fitbit folder (containing 11 csv files) seem to have a matching filename in the second Fitbit folder (containing 18 csv files), only with different time periods. 

Let's write all the file names into two text files with the command line:

```bash
ls > filelist_1.txt
ls > filelist_2.txt
```

I imported both text files into Google Sheets, pasted them side by side in two columns, then applied an Excel formula to check for identical filenames:

```excel
=IF(ISNUMBER(MATCH(A1, B:B, 0)), "Match", "No Match")
```

*Quick reminder on how the `MATCH()` function works in Excel and Google Sheets:*

* `MATCH()` checks if the value in cell A1 exists anywhere in Column B. The 0 at the end means it looks for an exact match.

* If a match is found, `MATCH()` returns the row number where it found the value in Column B. If no match is found, it returns an error (`#N/A`).

* `ISNUMBER()` checks if the return value is a number

*  `IF()` evaluates whether `ISNUMBER()` returns `TRUE` or `FALSE`, and displays `Match` or `No Match` accordingly.

I applied conditional formatting in Google Sheets to highlight cells with matching filenames, which confirmed that all the 11 files from the first folder had "twin" files in the second folder. The second folder contained an additional 7 files not found in the first.

#### Combining the "twin" files

After verifying the filenames, I concatenated the matching twin files using R and saved the combined files in the `Fitbit_Complete_Data` folder, along with the unmatched files. 

Sample code:

```r
# Looping through files to look for matching filenames ("twins")
for (file in unique(c(basename(files1), basename(files2)))) {
 
  # If there are twin files in folders 1 and 2, concat files
  if (file %in% basename(files1) & file %in% basename(files2)) {
    data1 <- read_csv(file.path(folder1, file))
    data2 <- read_csv(file.path(folder2, file))
   
    # Combine the data
    combined_data <- rbind(data1, data2)
   
    # Save the combined file in the "Fitbit_Complete_Data" folder
    write_csv(combined_data, here("BELLABEAT", "DATA", "Fitbit", "Fitbit_Complete_Data", paste0("combined_", file)))
   
  } else {
    # Copy the remaining non-matching files to the "Fitbit_Complete_Data" folder as well
    if (file %in% basename(files1)) {
      file.copy(file.path(folder1, file), here("BELLABEAT", "DATA", "Fitbit", "Fitbit_Complete_Data", file))
    } else {
      file.copy(file.path(folder2, file), here("BELLABEAT", "DATA", "Fitbit", "Fitbit_Complete_Data", file))
    }
  }
}

```
    
#### Verifying the file combination

To make sure the relevant files were successfully combined, I first checked the total number of files in the new `Fitbit_Complete_Data` folder using the following commands:

```bash
cd Fitbit_Complete_Data/
ls > total_files.txt
cat total_files.txt
wc -l total_files.txt
```

This confirmed a total of 18 Fitbit .csv files (11 combined twin files and 7 additional files from the second folder).

Next, I verified that the row count of each combined file matched the sum of the rows in the original twin files with an R script.


Sample code:

```R
# Get the list of combined files (only those starting with "combined_")
combined_files <- list.files(combined_dir, pattern = "^combined.*csv$", full.names = TRUE)


# Loop through combined files and check row counts
for (file in combined_files) {
  basefile <- basename(file)
  
  # Remove "combined_" prefix to match files in dir1 and dir2
  basefile_no_combined <- sub("combined_", "", basefile)
  
  # Read files from both directories and the combined directory
  data_combined <- read.csv(file)
  data_dir1 <- read.csv(file.path(dir1, basefile_no_combined))
  data_dir2 <- read.csv(file.path(dir2, basefile_no_combined))
  
  # Get row counts
  count_combined <- nrow(data_combined)
  count_dir1 <- nrow(data_dir1)
  count_dir2 <- nrow(data_dir2)
  
  # Calculate the expected total 
  expected_total <- count_dir1 + count_dir2
  
  # Calculate the difference
  diff <- expected_total - count_combined
  
  if (diff != 0) {
    cat("ERROR in count!")
  }
  
  # Output results
  cat("File:", basefile, "\n")
  cat("Dir 1 Count:", count_dir1, "\n")
  cat("Dir 2 Count:", count_dir2, "\n")
  cat("Expected total: ", expected_total, "\n")
  cat("Combined Count:", count_combined, "\n")
  cat("Difference in count is", diff, "\n")
  cat("----------------------------\n")
}
```

The row numbers matched, so that confirmed that data integrity was preserved.


### B) Survey

The Survey dataset contains one Excel file, so there was no need to prepare it further at this stage.


## 4. Datasets ready for cleaning

- Now, the Fitbit dataset is fully organized, with all the files stored in one unified folder called `DATA/Fitbit/Fitbit_Complete_Data`.
- The survey data is stored separately in a folder called `DATA/Survey`.


### A) `Fitbit_Complete_Data` folder

This folder contains 18 .csv files with data from March 12 to May 12, 2016, organized as follows:

File                     | Description
-------------------------|-----------------------------
`dailyActivity_merged.csv` | Daily summary of activity levels, steps, and calories burned.
`heartrate_seconds_merged.csv` | Second-by-second heart rate data.
`hourlyCalories_merged.csv` | Hourly calorie data.
`hourlyIntensities_merged.csv` | Hourly intensity data.
`hourlySteps_merged.csv` | Hourly step data.
`minuteCaloriesNarrow_merged.csv` | Narrow minute-level calorie data.
`minuteIntensitiesNarrow_merged.csv` | Narrow minute-level intensity data.
`minuteMETsNarrow_merged.csv` | Narrow minute-level MET data.
`minuteSleep_merged.csv` | Minute-level sleep data.
`minuteStepsNarrow_merged.csv` | Narrow minute-level step data.
`weightLogInfo_merged.csv` | Weight log information.
`dailyCalories_merged.csv` | Daily calorie data.
`dailyIntensities_merged.csv` | Daily intensity data.
`dailySteps_merged.csv` | Daily step data.
`minuteCaloriesWide_merged.csv` | Wide minute-level calorie data.
`minuteIntensitiesWide_merged.csv` | Wide minute-level intensity data.
`minuteStepsWide_merged.csv` | Wide minute-level step data.
`sleepDay_merged.csv` | Daily summary of sleep data.

### B) `Survey` folder

This folder contains:

- A `Data Report` PDF file providing the research context, names of the survey authors, etc.
- The original blank survey questionnaire (PDF).
- The actual dataset in Excel format.
  
The Excel file contains data collected from over 500 individuals between May and July 2020. It focuses on user opinions and interactions with their smart devices:

File                     | Description
-------------------------|-----------------------------
`Anonymized_UserRelationshipWithTheirSmartDevice_Dataset.xlsx` | User opinions and interactions with their smart devices.

The Excel file is in long (narrow) format.


## 5. Credibility and limitations

### A) Fitbit dataset

#### Context and authors

The Fitbit dataset was compiled and made publicly available by [Möbius](https://www.kaggle.com/arashnic) on [Kaggle](https://www.kaggle.com/datasets/arashnic/fitbit). The data was collected through Fitbit’s API, and generated by respondents to a distributed survey via Amazon Mechanical Turk between March 12, 2016, and May 12, 2016. Thirty eligible Fitbit users consented to share their personal tracker data. 

#### Limitations

The Fitbit dataset has four key limitations:

- Small sample size (30 users):
- Outdated data (collected in 2016): the dataset may not reflect current trends in smart device usage;
- Lack of gender differentiation: since Bellabeat focuses on women's health and wellness, the lack of gender-specific data makes it less relevant for this business task.
- Potential bias: Fitbit users might be more active than the general population, which could introduce bias in the analysis.


### B) Survey dataset

#### Context and authors

The survey dataset was conducted by [Francesco Lelli](https://francescolelli.info/) (Professor at Tilburg University, Netherlands) and [Heidi Toivonen](https://www.heiditoivonen.com/) (PostDoc at Ghent University) using the Qualtrics platform. Data was collected from over 500 participants between May and July 2020, with no specific pre-selection of respondents. 

#### Strengths

- Larger sample size (500+ participants);
- More recent data (collected in 2020);
- Gender differentiation: includes data that distinguishes between men and women (coded as '1' or '2'), which is what I need for Bellabeat, since it is a company focused 100% on women;
- Ethical approval: received a stamp of ethical approval (IRB EXE 2020-007) for data collection integrity and participant protection.
- Global collection: distributed globally, so there was a diverse pool of respondents.
- Psychological insights: adds an understanding of how users feel about their smart devices.

#### Limitations

However, the survey respondents might still represent a specific demographic and could limit the generalization of the results.



## 6. Data integrity and privacy

The Fitbit and Survey datasets are GDPR-compliant and do not contain any personally identifiable information. They are publicly available and licensed for open use (Fitbit data via Kaggle and the survey data via MDPI's open access). Both datasets have been downloaded and stored locally to preserve privacy and data integrity before moving to the cleaning phase.

Both datasets are now ready for the next phase, which is the Process (Cleaning) step.

